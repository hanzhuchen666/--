\chapter{矩阵分解}\label{MathTools:chap:matrix_decomposition}
\section{LU分解}\label{MathTools:sec:lu_decomposition}
\section{QR分解及HouseHolder方法}\label{MathTools:sec:qr_decomposition}
\subsection{HouseHolder方法}\label{MathTools:sec:householder}
\section{SVD奇异值分解}\label{MathTools:sec:svd}
% todo : SVD奇异值分解搬运
\begin{theorembox}
	$A = U\Sigma V^T$，其中$U$和$V^T$是酉矩阵，$\Sigma$是对角线矩阵
\end{theorembox}
\subsubsection{SVD分解应用于PCA主成份分析}
https://www.cnblogs.com/daniel-D/p/3218063.html
\chapter{矩阵的逆及其求解方式}\label{MathTools:chap:matrix_inverse}
\section{若尔当型}
\section{LU分解求解对称正定矩阵的逆}\label{MathTools:sec:lu_inverse}
\section{QR分解求解右伪逆}\label{MathTools:sec:qr_pseudoinverse}
\section{SVD分解求广义逆}\label{MathTools:sec:svd_pseudoinverse}

\chapter{函数最优化问题求解方式}\label{MathTools:chap:optimization}
\section{拉格朗日数乘法}
\section{原始牛顿法}\label{MathTools:sec:newton_method}
\section{雅可比矩阵和Hessian矩阵}\label{MathTools:sec:jacobian_hessian}
\section{高斯-牛顿法}\label{MathTools:sec:gauss_newton}
\section{拟牛顿法}\label{MathTools:sec:quasi_newton}
\subsection{Levenberg-Marquardt algorithm, LM}\label{MathTools:sec:lm}
\subsection{Davidon-Fletcher-Powell algoritm DFP}\label{MathTools:sec:dfp}
\subsection{Broyden–Fletcher–Goldfarb–Shanno algorithm BFGS}\label{MathTools:sec:bfgs}

\section{拉格朗日乘子法}
拉格朗日乘子法是解决带约束优化问题的经典方法。对于一个带约束的优化问题，它引入拉格朗日乘子，将约束条件融合到目标函数中，形成拉格朗日函数。然后，通过求解拉格朗日函数的一阶最优性条件（即拉格朗日函数的偏导数为零），得到可能的极值点。
\section{惩罚函数法}
惩罚函数法通过向目标函数中添加一个惩罚项来处理约束条件。当约束条件被违反时，惩罚项会增加目标函数的值，从而“惩罚”违反约束的行为。常用的惩罚函数包括二次惩罚函数和绝对值惩罚函数。
\section{扩展拉格朗日法}\label{MathTools::sec::AL}
增广拉格朗日法是拉格朗日乘子法和惩罚函数法的结合。它在拉格朗日函数的基础上，添加了额外的惩罚项，称为增广项。这个增广项通常是二次型的，用于改善算法的收敛性和稳定性。它的问题定义是：
\begin{gather*}
	\min_x \quad f(x) \\
	\text{s.t.} \ c(x)\{\leq , = \}0
\end{gather*}
		构造增广拉格朗日算子
		\begin{equation*}
			\mathcal{L}_A = f(x) + \lambda ^T c(x) + \frac{1}{2}c(x)^TI_\mu c(x)
		\end{equation*}其中$\lambda$是拉格朗日乘子$\mu$是惩罚系数。满足：
		\begin{equation*}
			I_\mu = 
			\begin{cases}
				0 \quad \text{if} c_i(x) < 0 \and \lambda_i = 0,i\in \mathcal{I}\\
				\mu_i \quad \text{otherwise}
			\end{cases} 
		\end{equation*}
\begin{theorembox}
	\begin{enumerate}
  \item 把$\lambda$和$\mu$当作常数，求解方程$\min_x\mathcal{L}_A(x,\lambda ,\mu)$
  \item 更新拉格朗日乘子
  \begin{equation*}
  	\lambda^{+}_i = \begin{cases}
  		\lambda_i + \mu_ic_i(x^\star) & i\in \mathcal{E} \\
  		\max(0,\lambda_i + \mu_i c_i(x^\star)) & i \in \mathcal{I}
  	\end{cases}
  \end{equation*}
  \item 更新惩罚项 $\mu^+ = \phi\mu, \ \phi > 1$，$\phi$通常取2到10之间
  \item 检查约束收敛性
  \item 如果达到了未达到容许度，执行第一步
\end{enumerate}

\end{theorembox}
\subsection{优点}
处理非凸问题：
增广拉格朗日法在处理非凸优化问题时，比拉格朗日乘子法更稳定，更容易收敛到全局最优解。
对约束的容忍性：
增广拉格朗日法对约束条件的违反有一定的容忍性，不会因为轻微的违反而导致算法失效。
较好的收敛性：
增广拉格朗日法通常比单纯的惩罚函数法具有更好的收敛性，可以更快地找到最优解。﻿
\subsection{缺点}
参数调整：
需要调整惩罚参数和拉格朗日乘子，选择合适的参数对于算法的性能至关重要。
计算复杂度：
对于复杂的优化问题，增广拉格朗日法的计算复杂度可能较高。
\subsection{应用领域}
增广拉格朗日法被广泛应用于各种优化问题，包括：
非线性规划:处理具有非线性约束的优化问题。
凸优化:用于解决凸优化问题，例如二次规划、线性规划等。
信号处理:在信号去噪、图像处理等领域有应用。
机器学习:在机器学习中，增广拉格朗日法被用于训练各种模型，例如支持向量机、神经网络等。


\chapter{未分类}
\section{条件数}
条件数是线性方程组Ax=b的解对b中的误差或不确定度的敏感性的度量。数学定义为矩阵A的条件数等于A的范数与A的逆的范数的乘积，即cond(A)=‖A‖·‖A-1‖，对应矩阵的3种范数，相应地可以定义3种条件数。

matlab 里面运算函数：cond(A,2)或cond(A):2范数

一个极端的例子，当A奇异时，条件数为无穷，这时即使不改变b，x也可以改变。奇异的本质原因在于矩阵有0特征值，x在对应特征向量的方向上运动不改变Ax的值。如果一个特征值比其它特征值在数量级上小很多，x在对应特征向量方向上很大的移动才能产生b微小的变化，这就解释了为什么这个矩阵为什么会有大的条件数，事实上，正规阵在二范数下的条件数就可以表示成 abs(最大特征值/最小特征值)。——摘自百度百科

在计算机编程环境中，数据都是有浮点类型表示，精度有限，存在干扰，因此在解线性方程的时候都会存在误差。

\subsection{病态矩阵与条件数}
% todo : 条件数与病态矩阵
https://www.cnblogs.com/daniel-D/p/3219802.html
\subsubsection{与特征值和SVD的关系}
\subsubsection{病态矩阵的处理方法}
5. 病态矩阵处理方法
真正的自由是建立在规范的基础上的。病态矩阵解集的不稳定性是由于解集空间包含了自由度过大的方向，解决这个问题的关键就是将这些方向去掉，而保留 scaling 较大的方向，从而把解集局限在一个较小的区域内。在上面的讨论中， A 矩阵的特征向量不一定正交，不适合做新基， SVD 分解正好分解出了正交基，可以选前 k 个 $v^T$ 向量作为正交基。

比如，现在只选取前一个 (0.707, 0.707) 方向作为基，解集局限咋 y = x 这条直线上。直观的解释就是， A 矩阵的两个列向量过于类似，我们就可以将它们等同看待，第一次 b = (1000, 0), 解集是(0.5, 0.5), 第二次 b = (1000, 0.001), 解集还是 (0.5, 0.5).

总结起来，解决 A 病态就是将解集限定在一组正交基空间内，即对于坐标 y， 选择 k 个正交基 Zk，解决问题：$$\min_{y}\Vert AZ_ky - b \Vert ^2$$
这个就是 reduce-rank model. 具体方法有 truncated SVD 和 Krylov subspace method。
\section{带约束的最小范数解问题}
问题定义：
\includegraphics{MathTools/assets/rinv_with_constraints.png}
\begin{theorembox}
	$x = (A^TA)^{-1}(A^Tb-C^T(C(A^TA)^{-1}C^T)^{-1}(C(A^TA)^{-1}A^Tb-d))$
\end{theorembox}
\section{酉矩阵}
https://zh.wikipedia.org/wiki/%E9%85%89%E7%9F%A9%E9%98%B5
\subsection{图形中的稀疏表示}
% todo : 图形中的稀疏表示